{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('reddit_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>pro_title</th>\n",
       "      <th>pro_selftext</th>\n",
       "      <th>lem_title</th>\n",
       "      <th>lem_selftext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>$TK &amp;amp; $TNK</td>\n",
       "      <td>Thoughts on Teekay (TK) &amp;amp; Teekay Tankers (...</td>\n",
       "      <td>1587476965</td>\n",
       "      <td>TK amp TNK</td>\n",
       "      <td>Thoughts on Teekay TK amp Teekay Tankers TNK T...</td>\n",
       "      <td>TK amp TNK</td>\n",
       "      <td>Thoughts on Teekay TK amp Teekay Tankers TNK T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Investing Frameworks</td>\n",
       "      <td>Are there any frameworks/ concepts that you ha...</td>\n",
       "      <td>1587474494</td>\n",
       "      <td>Investing Frameworks</td>\n",
       "      <td>Are there any frameworks concepts that you hav...</td>\n",
       "      <td>Investing Frameworks</td>\n",
       "      <td>Are there any framework concept that you have ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Long term growth calculation</td>\n",
       "      <td>Hi there, \\n\\n&amp;amp;#x200B;\\n\\nI want to valuat...</td>\n",
       "      <td>1587474287</td>\n",
       "      <td>Long term growth calculation</td>\n",
       "      <td>Hi there \\n\\nampx200B\\n\\nI want to valuate a c...</td>\n",
       "      <td>Long term growth calculation</td>\n",
       "      <td>Hi there ampx200B I want to valuate a company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Is this the perfect time for NEW companies to ...</td>\n",
       "      <td>This pandemic has demonstrated how badly thing...</td>\n",
       "      <td>1587473864</td>\n",
       "      <td>Is this the perfect time for NEW companies to ...</td>\n",
       "      <td>This pandemic has demonstrated how badly thing...</td>\n",
       "      <td>Is this the perfect time for NEW company to ta...</td>\n",
       "      <td>This pandemic ha demonstrated how badly thing ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Is anyone else losing faith in the stock market?</td>\n",
       "      <td>Maybe stocks will crash again, maybe stocks wi...</td>\n",
       "      <td>1587473142</td>\n",
       "      <td>Is anyone else losing faith in the stock market</td>\n",
       "      <td>Maybe stocks will crash again maybe stocks wil...</td>\n",
       "      <td>Is anyone else losing faith in the stock market</td>\n",
       "      <td>Maybe stock will crash again maybe stock will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit                                              title  \\\n",
       "0          1                                     $TK &amp; $TNK   \n",
       "1          1                               Investing Frameworks   \n",
       "2          1                       Long term growth calculation   \n",
       "3          1  Is this the perfect time for NEW companies to ...   \n",
       "4          1   Is anyone else losing faith in the stock market?   \n",
       "\n",
       "                                            selftext  created_utc  \\\n",
       "0  Thoughts on Teekay (TK) &amp; Teekay Tankers (...   1587476965   \n",
       "1  Are there any frameworks/ concepts that you ha...   1587474494   \n",
       "2  Hi there, \\n\\n&amp;#x200B;\\n\\nI want to valuat...   1587474287   \n",
       "3  This pandemic has demonstrated how badly thing...   1587473864   \n",
       "4  Maybe stocks will crash again, maybe stocks wi...   1587473142   \n",
       "\n",
       "                                           pro_title  \\\n",
       "0                                         TK amp TNK   \n",
       "1                               Investing Frameworks   \n",
       "2                       Long term growth calculation   \n",
       "3  Is this the perfect time for NEW companies to ...   \n",
       "4    Is anyone else losing faith in the stock market   \n",
       "\n",
       "                                        pro_selftext  \\\n",
       "0  Thoughts on Teekay TK amp Teekay Tankers TNK T...   \n",
       "1  Are there any frameworks concepts that you hav...   \n",
       "2  Hi there \\n\\nampx200B\\n\\nI want to valuate a c...   \n",
       "3  This pandemic has demonstrated how badly thing...   \n",
       "4  Maybe stocks will crash again maybe stocks wil...   \n",
       "\n",
       "                                           lem_title  \\\n",
       "0                                         TK amp TNK   \n",
       "1                               Investing Frameworks   \n",
       "2                       Long term growth calculation   \n",
       "3  Is this the perfect time for NEW company to ta...   \n",
       "4    Is anyone else losing faith in the stock market   \n",
       "\n",
       "                                        lem_selftext  \n",
       "0  Thoughts on Teekay TK amp Teekay Tankers TNK T...  \n",
       "1  Are there any framework concept that you have ...  \n",
       "2  Hi there ampx200B I want to valuate a company ...  \n",
       "3  This pandemic ha demonstrated how badly thing ...  \n",
       "4  Maybe stock will crash again maybe stock will ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit        0\n",
       "title            0\n",
       "selftext         0\n",
       "created_utc      0\n",
       "pro_title       27\n",
       "pro_selftext    67\n",
       "lem_title       29\n",
       "lem_selftext    67\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24400, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit       0\n",
       "title           0\n",
       "selftext        0\n",
       "created_utc     0\n",
       "pro_title       0\n",
       "pro_selftext    0\n",
       "lem_title       0\n",
       "lem_selftext    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['lem_title']\n",
    "y = data['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    stratify=y,\n",
    "                                                    test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17080,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17080,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cvec = cvec.fit_transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomal NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8803864168618267"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.fit(X_train_cvec, y_train)\n",
    "mnb.score(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8016393442622951"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase N Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_mnb = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=True)),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "tvec_gnb = make_pipeline(\n",
    "    TfidfVectorizer(stop_words=True),\n",
    "    FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    "    GaussianNB()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    'cvec__max_features': np.arange(500, 5_000, 250),\n",
    "      'cvec__stop_words': ['english'],\n",
    "     'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "            'mnb__alpha': [.75, 1.0, 1.25, 1.5, 2.0]\n",
    "}\n",
    "\n",
    "tvec_params = {\n",
    "    'tvec__max_features': np.arange(1_000, 8_000, 1_000),\n",
    "    'tvec__stop_words': ['english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2), (1,3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cvec_mnb = GridSearchCV(cvec_mnb, cvec_params, cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('cvec',\n",
       "                                        CountVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.int64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        preprocessor=None,\n",
       "                                                        stop_words=True,\n",
       "                                                        strip_accents=None,\n",
       "                                                        token_pattern='(?u...\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'cvec__max_features': array([ 500,  750, 1000, 1250, 1500, 1750, 2000, 2250, 2500, 2750, 3000,\n",
       "       3250, 3500, 3750, 4000, 4250, 4500, 4750]),\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'mnb__alpha': [0.75, 1.0, 1.25, 1.5, 2.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_mnb.fit(X_train,\n",
    "                y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8498829039812646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 4500,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'mnb__alpha': 1.25}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gs_cvec_mnb.score(X_train, y_train))\n",
    "gs_cvec_mnb.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7952185792349726"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cvec_mnb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_lr = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=True)),\n",
    "    ('lr', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    'cvec__max_features': np.arange(500, 5_000, 250),\n",
    "      'cvec__stop_words': ['english'],\n",
    "     'cvec__ngram_range': [(1,1), (1,2)],\n",
    "           'lr__penalty': ['l1', 'l2'],\n",
    "                 'lr__C': np.linspace(.001, 2, 10),\n",
    "            'lr__solver': ['liblinear']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cvec__max_features': 4750, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': 'english', 'lr__C': 0.44522222222222224, 'lr__penalty': 'l2', 'lr__solver': 'liblinear'}\n",
      "CPU times: user 1min 18s, sys: 10.9 s, total: 1min 29s\n",
      "Wall time: 4min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8568501170960188"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gs_lr = GridSearchCV(cvec_lr, cvec_params, cv=10, n_jobs=-1)\n",
    "\n",
    "gs_lr.fit(X_train, y_train)\n",
    "\n",
    "print(gs_lr.best_params_)\n",
    "gs_lr.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7896174863387978"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(ngram_range = (1,2), min_df = 2, \n",
    "                     stop_words='english')\n",
    "X_train_tvec = tv.fit_transform(X_train)\n",
    "X_test_tvec = tv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr_params = {\n",
    "    'lr__penalty': ['l1', 'l2'],\n",
    "          'lr__C': np.linspace(.001, 2, 10),\n",
    "     'lr__solver': ['liblinear']    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr = GridSearchCV(LogisticRegression(), \n",
    "                     param_grid = {\n",
    "                    'penalty': ['l1', 'l2'],\n",
    "                     'C': np.linspace(.001, 2, 10),\n",
    "                     'solver': ['liblinear']},\n",
    "                     cv=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-03, 2.23111111e-01, 4.45222222e-01, 6.67333333e-01,\n",
       "       8.89444444e-01, 1.11155556e+00, 1.33366667e+00, 1.55577778e+00,\n",
       "       1.77788889e+00, 2.00000000e+00]),\n",
       "                         'penalty': ['l1', 'l2'], 'solver': ['liblinear']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8842505854800937"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.score(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.796311475409836"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.3336666666666666, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    'cvec__max_features': np.arange(500, 5_000, 250),\n",
    "      'cvec__stop_words': ['english'],\n",
    "     'cvec__ngram_range': [(1,1), (1,2), (1, 3)],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_bagcl = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=True)),\n",
    "    ('bagcl', BaggingClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9565573770491803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 3750,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': 'english'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_bagcl = GridSearchCV(cvec_bagcl, cvec_params, cv=5, n_jobs=-1)\n",
    "gs_bagcl.fit(X_train, y_train)\n",
    "print(gs_bagcl.score(X_train, y_train))\n",
    "gs_bagcl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7487704918032787\n"
     ]
    }
   ],
   "source": [
    "print(gs_bagcl.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    'cvec__max_features': np.arange(500, 5_000, 250),\n",
    "      'cvec__stop_words': ['english'],\n",
    "     'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "           'svc__degree': [2]\n",
    "}\n",
    "cvec_svc = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=True)),\n",
    "    ('svc', SVC())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_svm_cvec = GridSearchCV(cvec_svc, cvec_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921135831381733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 4750,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'svc__degree': 2}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm_cvec.fit(X_train, y_train)\n",
    "print(gs_svm_cvec.score(X_train, y_train))\n",
    "gs_svm_cvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7897540983606557"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm_cvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gs_svm_tvec = GridSearchCV(SVC(), param_grid = {'degree': [2]},\n",
    "                                            cv=5,\n",
    "                                            n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.5 s, sys: 379 ms, total: 32.9 s\n",
      "Wall time: 52.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9522248243559719"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gs_svm_tvec.fit(X_train_tvec, y_train)\n",
    "gs_svm_tvec.score(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7974043715846995"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_svm_tvec.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_params = {\n",
    "    'cvec__max_features': np.arange(500, 3_000, 500),\n",
    "      'cvec__stop_words': ['english'],\n",
    "     'cvec__ngram_range': [(1,1), (1,2), (1,3)],\n",
    "     'rfc__n_estimators': [50, 100],\n",
    "'rfc__min_samples_split': [3],\n",
    " 'rfc__min_samples_leaf': [2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_rfc = Pipeline([\n",
    "    ('cvec', CountVectorizer(stop_words=True)),\n",
    "    ('rfc', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29 µs, sys: 0 ns, total: 29 µs\n",
      "Wall time: 32.9 µs\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gs_rfc_cvec = GridSearchCV(cvec_rfc, \n",
    "                           param_grid=cvec_params,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/derekmcadam/opt/anaconda3/envs/dsi/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8371779859484777\n",
      "CPU times: user 5.67 s, sys: 500 ms, total: 6.17 s\n",
      "Wall time: 48.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': 2500,\n",
       " 'cvec__ngram_range': (1, 3),\n",
       " 'cvec__stop_words': 'english',\n",
       " 'rfc__min_samples_leaf': 2,\n",
       " 'rfc__min_samples_split': 3,\n",
       " 'rfc__n_estimators': 50}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gs_rfc_cvec.fit(X_train, y_train)\n",
    "print(gs_rfc_cvec.score(X_train, y_train))\n",
    "gs_rfc_cvec.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7886612021857924"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc_cvec.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730093676814988\n",
      "CPU times: user 14.1 s, sys: 249 ms, total: 14.3 s\n",
      "Wall time: 9.19 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_samples_leaf': 2,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': -1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "gs_rfc_tvec = GridSearchCV(RandomForestClassifier(), \n",
    "                      param_grid={'n_estimators': [50, 100],\n",
    "                      'n_jobs': [-1],\n",
    "                      'min_samples_split': [3],\n",
    "                      'min_samples_leaf': [2]})\n",
    "\n",
    "gs_rfc_tvec.fit(X_train_tvec, y_train)\n",
    "print(gs_rfc_tvec.score(X_train_tvec, y_train))\n",
    "gs_rfc_tvec.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7882513661202186"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rfc_tvec.score(X_test_tvec, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('dsi': conda)",
   "language": "python",
   "name": "python37764bitdsicondaddfe0c05640c4e1581da44e0f6b96ae5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
